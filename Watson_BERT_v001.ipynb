{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Watson_BERT_v001.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOePNMXdupqt1EI/lsdad8o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gkv856/KaggleData/blob/main/Watson_BERT_v001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hQT14a1MmHd"
      },
      "source": [
        "import tensorflow as tf\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aARKaY5PcTL",
        "outputId": "bf1e7f0e-8c61-4191-a786-6169dab1326e"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.10.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.17)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZjBwi_NRNjz"
      },
      "source": [
        "from transformers import BertTokenizer, TFBertModel\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET73-43ARjGW"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJtSelKERODa"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBqGZ93FPknQ"
      },
      "source": [
        "TRAIN_URL = \"https://raw.githubusercontent.com/gkv856/KaggleData/main/watson_train.csv\"\n",
        "# TRAIN_URL =\"https://raw.githubusercontent.com/gkv856/KaggleData/main/train.csv\"\n",
        "train = pd.read_csv(TRAIN_URL)"
      ],
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "ft2jSsS-EqOA",
        "outputId": "2d5f1182-02f1-4be4-eb65-2a04fa76836c"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>lang_abv</th>\n",
              "      <th>language</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5130fd2cb5</td>\n",
              "      <td>and these comments were considered in formulat...</td>\n",
              "      <td>The rules developed in the interim were put to...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5b72532a0b</td>\n",
              "      <td>These are issues that we wrestle with in pract...</td>\n",
              "      <td>Practice groups are not permitted to work on t...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3931fbe82a</td>\n",
              "      <td>Des petites choses comme celles-là font une di...</td>\n",
              "      <td>J'essayais d'accomplir quelque chose.</td>\n",
              "      <td>fr</td>\n",
              "      <td>French</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5622f0c60b</td>\n",
              "      <td>you know they can't really defend themselves l...</td>\n",
              "      <td>They can't defend themselves because of their ...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>86aaa48b45</td>\n",
              "      <td>ในการเล่นบทบาทสมมุติก็เช่นกัน โอกาสที่จะได้แสด...</td>\n",
              "      <td>เด็กสามารถเห็นได้ว่าชาติพันธุ์แตกต่างกันอย่างไร</td>\n",
              "      <td>th</td>\n",
              "      <td>Thai</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  ... label\n",
              "0  5130fd2cb5  ...     0\n",
              "1  5b72532a0b  ...     2\n",
              "2  3931fbe82a  ...     0\n",
              "3  5622f0c60b  ...     0\n",
              "4  86aaa48b45  ...     1\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_kZO1StEt2i",
        "outputId": "7256bf8f-340c-4bbc-8a5b-8a365af4a86a"
      },
      "source": [
        "# later you can use the whole data for traiing and test\n",
        "# train_df, valid_df = train_test_split(train, \n",
        "#                                        random_state=42, \n",
        "#                                       #  train_size=0.9, \n",
        "#                                        test_size=.25,\n",
        "#                                        stratify=train[[\"label\", \"lang_abv\"]].values)\n",
        "\n",
        "# use the below structure for testing if the data is huge\n",
        "train_df, remaining = train_test_split(train, \n",
        "                                       random_state=42, \n",
        "                                       train_size=0.0095, \n",
        "                                       stratify=train[[\"label\", \"lang_abv\"]].values)\n",
        "\n",
        "valid_df, _ = train_test_split(remaining, \n",
        "                              random_state=42, \n",
        "                              train_size=0.0095, \n",
        "                              stratify=remaining[[\"label\", \"lang_abv\"]].values)\n",
        "len(train_df), len(valid_df)"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(115, 114)"
            ]
          },
          "metadata": {},
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLC7QZq-E3nm",
        "outputId": "8a0ff3e6-d9f5-48f3-e389-b4dedb445e7c"
      },
      "source": [
        "# creating datasets\n",
        "with tf.device('/cpu:0'):\n",
        "  train_data = tf.data.Dataset.from_tensor_slices(((train_df[[\"premise\", \"hypothesis\"]].values), \n",
        "                                                   train_df[\"label\"].values))\n",
        "  \n",
        "  # test_data = tf.data.Dataset.from_tensor_slices((valid_df[\"premise\"].values,\n",
        "  #                                                  valid_df[\"label\"].values))\n",
        "train_data#, test_data"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: ((2,), ()), types: (tf.string, tf.int64)>"
            ]
          },
          "metadata": {},
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arm7gTECE-3s",
        "outputId": "bd544689-6447-4e64-f046-08620d9a2757"
      },
      "source": [
        "for d, label in train_data.take(4):\n",
        "    print(d, label)\n",
        "    print(\"\\n\")\n"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'\\xd8\\xb4\\xd8\\xa7\\xda\\xa9\\xd8\\xb1 \\xda\\xa9\\xd9\\x88 \\xdb\\x81\\xd8\\xb3\\xd9\\xbe\\xd8\\xa7\\xd9\\x86\\xd9\\x88\\xdb\\x8c \\xd8\\xad\\xda\\xa9\\xd8\\xa7\\xd9\\x85 \\xd9\\x86\\xdb\\x92 \\xd9\\x81\\xd8\\xa7\\xd8\\xb1\\xdb\\x8c\\xda\\x88 \\xdb\\x81\\xd9\\x84\\xd8\\xa7\\xd9\\x84\\xdb\\x8c \\xda\\xa9\\xdb\\x92 \\xd8\\xb7\\xd9\\x88\\xd8\\xb1 \\xd9\\xbe\\xd8\\xb1 \\xd8\\xb4\\xd9\\x86\\xd8\\xa7\\xd8\\xae\\xd8\\xaa \\xda\\xa9\\xdb\\x8c\\xd8\\xa7 \\xdb\\x81\\xdb\\x92.'\n",
            " b'\\xd8\\xb4\\xd8\\xa7\\xda\\xa9\\xd8\\xb1 \\xda\\xa9\\xd8\\xa7  \\xd8\\xa7\\xdb\\x8c\\xda\\xa9 \\xd8\\xba\\xd9\\x84\\xd8\\xb7 \\xd9\\x86\\xd8\\xa7\\xd9\\x85 \\xd8\\xaa\\xda\\xbe\\xd8\\xa7 \\xd8\\xac\\xd9\\x88 \\xd8\\xb3\\xd8\\xa7\\xd9\\x84\\xd9\\x88\\xda\\xba \\xd8\\xb3\\xdb\\x92 \\xd8\\xba\\xdb\\x8c\\xd8\\xb1 \\xd9\\x85\\xd8\\xaa\\xd9\\x88\\xd8\\xac\\xdb\\x81 \\xd8\\xb1\\xdb\\x81\\xd8\\xa7.'], shape=(2,), dtype=string) tf.Tensor(1, shape=(), dtype=int64)\n",
            "\n",
            "\n",
            "tf.Tensor(\n",
            "[b'\\xe0\\xa4\\x94\\xe0\\xa4\\xb0, \\xe0\\xa4\\xb5\\xe0\\xa5\\x8b \\xe0\\xa4\\xa5\\xe0\\xa5\\x8b\\xe0\\xa5\\x9c\\xe0\\xa4\\xbe \\xe0\\xa4\\x85\\xe0\\xa4\\xb2\\xe0\\xa4\\x97 \\xe0\\xa4\\xb9\\xe0\\xa5\\x88, \\xe0\\xa4\\x9c\\xe0\\xa5\\x88\\xe0\\xa4\\xb8\\xe0\\xa5\\x87 \\xe0\\xa4\\xb9\\xe0\\xa4\\xb0 \\xe0\\xa4\\x8f\\xe0\\xa4\\x95 \\xe0\\xa4\\x95\\xe0\\xa5\\x8d\\xe0\\xa4\\xb2\\xe0\\xa4\\xbe\\xe0\\xa4\\x87\\xe0\\xa4\\x82\\xe0\\xa4\\x9f \\xe0\\xa4\\x95\\xe0\\xa5\\x87 \\xe0\\xa4\\xa8\\xe0\\xa5\\x80\\xe0\\xa4\\x9a\\xe0\\xa5\\x87, \\xe0\\xa4\\x89\\xe0\\xa4\\xa8\\xe0\\xa5\\x8d\\xe0\\xa4\\xb9\\xe0\\xa5\\x80 \\xe0\\xa4\\x95\\xe0\\xa5\\x87 \\xe0\\xa4\\xb8\\xe0\\xa4\\xb0\\xe0\\xa5\\x87 \\xe0\\xa4\\xab\\xe0\\xa4\\xbe\\xe0\\xa4\\x87\\xe0\\xa4\\xb2\\xe0\\xa5\\x8d\\xe0\\xa4\\xb8 \\xe0\\xa4\\xb9\\xe0\\xa5\\x88 \\xe0\\xa5\\xa4'\n",
            " b'Unke paas waisi koi files nahi hai'], shape=(2,), dtype=string) tf.Tensor(2, shape=(), dtype=int64)\n",
            "\n",
            "\n",
            "tf.Tensor([b'Kusisitiza ni kama ibada.' b'Kuwa thabiti ni kama kufanya mila.'], shape=(2,), dtype=string) tf.Tensor(0, shape=(), dtype=int64)\n",
            "\n",
            "\n",
            "tf.Tensor(\n",
            "[b' The tents had been burned, but there was a new building where the main tent had been.'\n",
            " b'The tents had replaced the building.'], shape=(2,), dtype=string) tf.Tensor(2, shape=(), dtype=int64)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaekRPaHF5rm"
      },
      "source": [
        "\"\"\"\n",
        "Each line of the dataset is composed of the review text and its label\n",
        "- Data preprocessing consists of transforming text to BERT input features:\n",
        "input_word_ids, input_mask, segment_ids\n",
        "- In the process, tokenizing the text is done with the provided BERT model tokenizer\n",
        "\"\"\"\n",
        "\n",
        "# Label categories, right now our data has these categories\n",
        "label_list = [0, 1, 2]\n",
        "\n",
        "# maximum length of (token) input sequences, or the words in a question\n",
        "# to save speed we should reset this\n",
        "max_seq_length = 128\n",
        "\n",
        "train_batch_size = 32"
      ],
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3vOBS8iGCPr"
      },
      "source": [
        "model_name = 'bert-base-multilingual-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtkFhb5kGLYw"
      },
      "source": [
        "def encode_sentence(s, is_cls=False):\n",
        "   tokens = tokenizer.tokenize(s)\n",
        "   if not is_cls:\n",
        "    tokens.append('[SEP]')\n",
        "   return tokenizer.convert_tokens_to_ids(tokens)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42nuCApgGP8_",
        "outputId": "6f5016c1-47ef-4915-b128-6498af7371e1"
      },
      "source": [
        "tf.convert_to_tensor(encode_sentence(\"i love machine learning\"), dtype=tf.int32)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([  177, 16138, 21432, 26901,   102], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcGrT5YBGTk8"
      },
      "source": [
        "def pad_tokens(t1, t2, max_seq_length=max_seq_length):\n",
        "  \n",
        "  half_len_t1 = max_seq_length // 2 - 1\n",
        "  half_len_t2 = max_seq_length // 2\n",
        "  \n",
        "  frt = [t1[0]]\n",
        "  lst = [t1[-1]]\n",
        "  t1 = t1[1:-1]\n",
        "  t1 = frt +t1[1:half_len_t1-1]  + lst\n",
        "  # print(t1)\n",
        "\n",
        "  lst = [t2[-1]]\n",
        "  t2 = t2[0:-1]\n",
        "  t2 = t2[1:half_len_t2]  + lst\n",
        "  # print(t2)\n",
        "\n",
        "\n",
        "  len_t1 = len(t1)\n",
        "  len_t2 = len(t2)\n",
        "\n",
        "  if len_t1 < half_len_t1:\n",
        "    len_pad = half_len_t1 - len_t1\n",
        "    lst = [0] * len_pad\n",
        "    zeros = tf.constant(lst, dtype=tf.int32)\n",
        "    t1 = tf.concat([t1, zeros], axis=0) \n",
        "\n",
        "  if len_t2 < half_len_t2:\n",
        "    len_pad = half_len_t2 - len_t2\n",
        "    lst = [0] * len_pad\n",
        "    zeros = tf.constant(lst, dtype=tf.int32)\n",
        "    t2 = tf.concat([t2, zeros], axis=0)\n",
        "  \n",
        "  return t1, t2\n",
        "\n",
        "def to_feature(texta, textb, label):#, tokenizer=tokenizer):\n",
        "  hypothese = texta.numpy().decode('UTF-8')\n",
        "  premise = textb.numpy().decode('UTF-8')\n",
        "  \n",
        "  cls = encode_sentence(\"[CLS]\", is_cls=True)\n",
        "  \n",
        "  sentence1 = encode_sentence(hypothese)\n",
        "  sentence2 = encode_sentence(premise)\n",
        "  \n",
        "  sentence1, sentence2  = pad_tokens(sentence1, sentence2, max_seq_length=128)\n",
        "  \n",
        "\n",
        "  sentence1 = tf.convert_to_tensor(sentence1, dtype=tf.int32)\n",
        "  sentence2 = tf.convert_to_tensor(sentence2, dtype=tf.int32)\n",
        "  \n",
        "\n",
        "  input_word_ids = tf.concat([cls, sentence1, sentence2], axis=0)\n",
        "  input_mask = tf.ones_like(input_word_ids, dtype=tf.int32)\n",
        "\n",
        "  type_cls = tf.zeros_like(cls, dtype=tf.int32)\n",
        "  type_s1 = tf.zeros_like(sentence1, dtype=tf.int32)\n",
        "  type_s2 = tf.ones_like(sentence2, dtype=tf.int32)\n",
        "\n",
        "  input_type_ids = tf.concat([type_cls, type_s1, type_s2], axis=-1) \n",
        "\n",
        "\n",
        "  label = tf.cast(label, dtype=tf.int32)\n",
        "\n",
        "\n",
        "  return (input_word_ids, input_mask, input_type_ids, label)\n"
      ],
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlRXX_m9Gb7u"
      },
      "source": [
        "def to_feature_map(texta, textb, label):\n",
        "  #     print(text, label)\n",
        "  out = tf.py_function(to_feature, inp=[texta, textb, label], Tout=[tf.int32, tf.int32, tf.int32, tf.int32])\n",
        "  \n",
        "  iids, imask, segids, label = out[0], out[1], out[2], out[3]\n",
        "\n",
        " \n",
        "  x = {\n",
        "    \"input_word_ids\": iids,\n",
        "    \"input_mask\": imask,\n",
        "    \"input_type_ids\": segids\n",
        "  }\n",
        "  return (x, label)"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p267rcvOZulj",
        "outputId": "6be9e9cc-ba60-407b-fa24-24ba9055e915"
      },
      "source": [
        "t = \"1 2 3 4 5 6 7 8 9 10\"\n",
        "# t = \"\"\n",
        "x = to_feature_map(t, t, 4 )\n",
        "x"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'input_mask': <tf.Tensor: shape=(128,), dtype=int32, numpy=\n",
              "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              "  'input_type_ids': <tf.Tensor: shape=(128,), dtype=int32, numpy=\n",
              "  array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              "  'input_word_ids': <tf.Tensor: shape=(128,), dtype=int32, numpy=\n",
              "  array([  101,   122,   124,   125,   126,   127,   128,   129,   130,\n",
              "         10150,   102,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,   123,   124,   125,   126,   127,   128,   129,   130,\n",
              "         10150,   102,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0], dtype=int32)>},\n",
              " <tf.Tensor: shape=(), dtype=int32, numpy=4>)"
            ]
          },
          "metadata": {},
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDrM229KGgEy",
        "outputId": "ec4b602f-ea9a-408c-9fee-d9b2523ed162"
      },
      "source": [
        "s = train_data.take(1)\n",
        "for t, l in s:\n",
        "  inps = to_feature_map(t[0], t[1], l)[0]  \n",
        "  print(inps[\"input_word_ids\"].shape, inps[\"input_mask\"].shape, inps[\"input_type_ids\"].shape)"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128,) (128,) (128,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd5A-ewsGjn0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}